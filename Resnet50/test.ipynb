{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在验证数据完整性...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167017/167017 [00:10<00:00, 16271.12it/s]\n",
      "c:\\Users\\wyz20\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wyz20\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效数据量: 167017\n",
      "有效类别数: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Train]:   5%|▌         | 449/8351 [01:49<34:41,  3.80it/s, loss=6.76, acc=0.001]  c:\\Users\\wyz20\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Epoch 1/30 [Train]: 100%|██████████| 8351/8351 [41:04<00:00,  3.39it/s, loss=6.38, acc=0.013]  \n",
      "Epoch 1/30 [Test]: 100%|██████████| 2088/2088 [12:44<00:00,  2.73it/s, acc=0.044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Train]: 100%|██████████| 8351/8351 [41:21<00:00,  3.37it/s, loss=5.88, acc=0.070]  \n",
      "Epoch 2/30 [Test]: 100%|██████████| 2088/2088 [10:38<00:00,  3.27it/s, acc=0.143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.1430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Train]: 100%|██████████| 8351/8351 [45:54<00:00,  3.03it/s, loss=5.22, acc=0.144]  \n",
      "Epoch 3/30 [Test]: 100%|██████████| 2088/2088 [13:19<00:00,  2.61it/s, acc=0.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Train]: 100%|██████████| 8351/8351 [47:22<00:00,  2.94it/s, loss=4.64, acc=0.202]  \n",
      "Epoch 4/30 [Test]: 100%|██████████| 2088/2088 [13:16<00:00,  2.62it/s, acc=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.2573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]: 100%|██████████| 8351/8351 [45:44<00:00,  3.04it/s, loss=3.64, acc=0.248]  \n",
      "Epoch 5/30 [Test]: 100%|██████████| 2088/2088 [10:40<00:00,  3.26it/s, acc=0.318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.3182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 8351/8351 [45:32<00:00,  3.06it/s, loss=5.02, acc=0.287]  \n",
      "Epoch 6/30 [Test]: 100%|██████████| 2088/2088 [13:20<00:00,  2.61it/s, acc=0.360]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.3604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]: 100%|██████████| 8351/8351 [47:21<00:00,  2.94it/s, loss=3.87, acc=0.322]  \n",
      "Epoch 7/30 [Test]: 100%|██████████| 2088/2088 [13:17<00:00,  2.62it/s, acc=0.386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.3858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|██████████| 8351/8351 [45:40<00:00,  3.05it/s, loss=2.6, acc=0.351]   \n",
      "Epoch 8/30 [Test]: 100%|██████████| 2088/2088 [10:38<00:00,  3.27it/s, acc=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.3979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|██████████| 8351/8351 [45:43<00:00,  3.04it/s, loss=2.41, acc=0.375]  \n",
      "Epoch 9/30 [Test]: 100%|██████████| 2088/2088 [13:27<00:00,  2.59it/s, acc=0.430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|██████████| 8351/8351 [45:54<00:00,  3.03it/s, loss=3.79, acc=0.397]  \n",
      "Epoch 10/30 [Test]: 100%|██████████| 2088/2088 [10:38<00:00,  3.27it/s, acc=0.443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 8351/8351 [46:52<00:00,  2.97it/s, loss=1.47, acc=0.417]  \n",
      "Epoch 11/30 [Test]: 100%|██████████| 2088/2088 [13:25<00:00,  2.59it/s, acc=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]: 100%|██████████| 8351/8351 [46:54<00:00,  2.97it/s, loss=2.6, acc=0.432]   \n",
      "Epoch 12/30 [Test]: 100%|██████████| 2088/2088 [13:21<00:00,  2.61it/s, acc=0.470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]: 100%|██████████| 8351/8351 [47:27<00:00,  2.93it/s, loss=3.38, acc=0.449]  \n",
      "Epoch 13/30 [Test]: 100%|██████████| 2088/2088 [13:39<00:00,  2.55it/s, acc=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Train]: 100%|██████████| 8351/8351 [48:09<00:00,  2.89it/s, loss=1.67, acc=0.464]   \n",
      "Epoch 14/30 [Test]: 100%|██████████| 2088/2088 [13:40<00:00,  2.55it/s, acc=0.491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 [Train]: 100%|██████████| 8351/8351 [47:51<00:00,  2.91it/s, loss=4.59, acc=0.477]  \n",
      "Epoch 15/30 [Test]: 100%|██████████| 2088/2088 [13:41<00:00,  2.54it/s, acc=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.4925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 [Train]: 100%|██████████| 8351/8351 [47:47<00:00,  2.91it/s, loss=2.54, acc=0.490]  \n",
      "Epoch 16/30 [Test]: 100%|██████████| 2088/2088 [13:46<00:00,  2.53it/s, acc=0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 [Train]: 100%|██████████| 8351/8351 [47:55<00:00,  2.90it/s, loss=2.31, acc=0.501]  \n",
      "Epoch 17/30 [Test]: 100%|██████████| 2088/2088 [13:43<00:00,  2.54it/s, acc=0.505]\n",
      "Epoch 18/30 [Train]: 100%|██████████| 8351/8351 [47:34<00:00,  2.93it/s, loss=2.37, acc=0.514]  \n",
      "Epoch 18/30 [Test]: 100%|██████████| 2088/2088 [13:43<00:00,  2.54it/s, acc=0.515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 [Train]: 100%|██████████| 8351/8351 [48:06<00:00,  2.89it/s, loss=2.17, acc=0.524]   \n",
      "Epoch 19/30 [Test]: 100%|██████████| 2088/2088 [13:19<00:00,  2.61it/s, acc=0.523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 [Train]: 100%|██████████| 8351/8351 [49:30<00:00,  2.81it/s, loss=2.02, acc=0.532]   \n",
      "Epoch 20/30 [Test]: 100%|██████████| 2088/2088 [13:17<00:00,  2.62it/s, acc=0.522]\n",
      "Epoch 21/30 [Train]: 100%|██████████| 8351/8351 [49:04<00:00,  2.84it/s, loss=1.95, acc=0.544]   \n",
      "Epoch 21/30 [Test]: 100%|██████████| 2088/2088 [13:29<00:00,  2.58it/s, acc=0.526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 [Train]: 100%|██████████| 8351/8351 [48:38<00:00,  2.86it/s, loss=2.04, acc=0.553]   \n",
      "Epoch 22/30 [Test]: 100%|██████████| 2088/2088 [13:41<00:00,  2.54it/s, acc=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 [Train]: 100%|██████████| 8351/8351 [48:12<00:00,  2.89it/s, loss=2.03, acc=0.560]   \n",
      "Epoch 23/30 [Test]: 100%|██████████| 2088/2088 [13:38<00:00,  2.55it/s, acc=0.538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 [Train]: 100%|██████████| 8351/8351 [50:28<00:00,  2.76it/s, loss=3.72, acc=0.572]   \n",
      "Epoch 24/30 [Test]: 100%|██████████| 2088/2088 [13:34<00:00,  2.56it/s, acc=0.535]\n",
      "Epoch 25/30 [Train]: 100%|██████████| 8351/8351 [47:03<00:00,  2.96it/s, loss=1.59, acc=0.578]   \n",
      "Epoch 25/30 [Test]: 100%|██████████| 2088/2088 [13:39<00:00,  2.55it/s, acc=0.530]\n",
      "Epoch 26/30 [Train]: 100%|██████████| 8351/8351 [47:16<00:00,  2.94it/s, loss=1.6, acc=0.589]    \n",
      "Epoch 26/30 [Test]: 100%|██████████| 2088/2088 [13:45<00:00,  2.53it/s, acc=0.534]\n",
      "Epoch 27/30 [Train]: 100%|██████████| 8351/8351 [49:57<00:00,  2.79it/s, loss=2.54, acc=0.595]   \n",
      "Epoch 27/30 [Test]: 100%|██████████| 2088/2088 [13:34<00:00,  2.56it/s, acc=0.544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 [Train]: 100%|██████████| 8351/8351 [48:04<00:00,  2.90it/s, loss=1.16, acc=0.604]   \n",
      "Epoch 28/30 [Test]: 100%|██████████| 2088/2088 [13:36<00:00,  2.56it/s, acc=0.549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 [Train]: 100%|██████████| 8351/8351 [48:47<00:00,  2.85it/s, loss=0.869, acc=0.608]  \n",
      "Epoch 29/30 [Test]: 100%|██████████| 2088/2088 [12:33<00:00,  2.77it/s, acc=0.543]\n",
      "Epoch 30/30 [Train]: 100%|██████████| 8351/8351 [46:21<00:00,  3.00it/s, loss=1.67, acc=0.617]   \n",
      "Epoch 30/30 [Test]: 100%|██████████| 2088/2088 [10:52<00:00,  3.20it/s, acc=0.545]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'tqdm' has no attribute 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 235\u001b[0m\n\u001b[0;32m    232\u001b[0m train_model(model, train_loader, test_loader)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# 生成预测结果\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m predict(model, test_loader)\n",
      "Cell \u001b[1;32mIn[4], line 190\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, test_loader)\u001b[0m\n\u001b[0;32m    187\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 190\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m inputs, _ \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(test_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicting\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    191\u001b[0m \t\tinputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(CFG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    192\u001b[0m \t\toutputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'tqdm' has no attribute 'tqdm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyparsing import C\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 参数配置\n",
    "CFG = {\n",
    "\t'data_path': 'chinese-medicine-image',\n",
    "\t'csv_name': 'train_labels.csv',\n",
    "\t'batch_size': 16,        # 根据显存调整\n",
    "\t'num_workers': 0,\n",
    "\t'num_epochs': 30,\n",
    "\t'lr': 3e-4,\n",
    "\t'image_size': 224,\n",
    "\t'num_classes': 881,\n",
    "\t'device': torch.device('cuda'),\n",
    "\t'seed': 42\n",
    "}\n",
    "\n",
    "# 数据预处理\n",
    "train_transform = transforms.Compose([\n",
    "\ttransforms.RandomResizedCrop(CFG['image_size']),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "\ttransforms.Resize(256),\n",
    "\ttransforms.CenterCrop(CFG['image_size']),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 自定义数据集\n",
    "class MedicineDataset(Dataset):\n",
    "\tdef __init__(self, df, transform=None):\n",
    "\t\tself.df = df\n",
    "\t\tself.transform = transform\n",
    "\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.df)\n",
    "\t\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\timg_path = self.df.iloc[idx, 0]\n",
    "\t\tlabel = self.df.iloc[idx, 1] - 1  # 标签转换为0-based\n",
    "\t\t\n",
    "\t\t# 关键断言\n",
    "\t\tassert 0 <= label < CFG['num_classes'], \\\n",
    "\t\t\tf\"无效标签：{label+1} (应为1-{CFG['num_classes']}), 位置：{idx}\"\n",
    "\t\timg = Image.open(img_path).convert('RGB')\n",
    "\t\tif self.transform:\n",
    "\t\t\timg = self.transform(img)\n",
    "\t\tlabel = torch.tensor(label, dtype=torch.long)  # 确保label为long类型\n",
    "\t\treturn img, label\n",
    "\n",
    "# 准备数据\n",
    "def load_data(csv_path, root_dir):\n",
    "\t# 改进的CSV读取方式\n",
    "\tdf = pd.read_csv(csv_path, header=0)  # 使用第一行作为列头\n",
    "\tdf = df.rename(columns={'ID': 'path', 'Label': 'label'})  # 规范列名\n",
    "\t\n",
    "\t# 数据类型转换\n",
    "\tconvert_dict = {'path': str, 'label': int}\n",
    "\tdf = df.astype(convert_dict)\n",
    "\t\n",
    "\t# 路径修正（根据实际文件结构可能需要调整）\n",
    "\tdf['path'] = df['path'].apply(lambda x: os.path.join(root_dir, x))\n",
    "\t\n",
    "\t# 验证数据有效性\n",
    "\tprint(\"正在验证数据完整性...\")\n",
    "\tvalid_samples = []\n",
    "\tfor idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "\t\tif os.path.exists(row['path']):\n",
    "\t\t\tvalid_samples.append(idx)\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"警告：缺失文件 {row['path']}\")\n",
    "\tdf = df.loc[valid_samples]\n",
    "\t\n",
    "\t# 过滤无效类别（每个类别至少需要2个样本）\n",
    "\tlabel_counts = df['label'].value_counts()\n",
    "\tvalid_labels = label_counts[label_counts >= 2].index\n",
    "\tdf = df[df['label'].isin(valid_labels)]\n",
    "\t\n",
    "\tprint(f\"有效数据量: {len(df)}\")\n",
    "\tprint(f\"有效类别数: {df['label'].nunique()}\")\n",
    "\t\n",
    "\t# 转换为0-based标签\n",
    "\t\n",
    "\t# 分层划分数据集\n",
    "\ttrain_df, val_df = train_test_split(\n",
    "\t\tdf,\n",
    "\t\ttest_size=0.2,\n",
    "\t\tstratify=df['label'],\n",
    "\t\trandom_state=CFG['seed']\n",
    "\t)\n",
    "\treturn train_df, val_df\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, test_loader):\n",
    "\tmodel = model.to(CFG['device'])\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\toptimizer = optim.Adam(model.parameters(), lr=CFG['lr'])\n",
    "\t\n",
    "\tbest_acc = 0.0\n",
    "\tfor epoch in range(CFG['num_epochs']):\n",
    "\t\t# 训练阶段\n",
    "\t\tmodel.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\t\t\n",
    "\t\tpbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{CFG[\"num_epochs\"]} [Train]')\n",
    "\t\tfor inputs, labels in pbar:\n",
    "\t\t\tinputs = inputs.to(CFG['device'])\n",
    "\t\t\tlabels = labels.to(CFG['device'])\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(inputs)\n",
    "\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\trunning_loss += loss.item() * inputs.size(0)\n",
    "\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\t\ttotal += labels.size(0)\n",
    "\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\t\t\t\n",
    "\t\t\tpbar.set_postfix({\n",
    "\t\t\t\t'loss': loss.item(),\n",
    "\t\t\t\t'acc': f'{correct/total:.3f}'\n",
    "\t\t\t})\n",
    "\t\t\n",
    "\t\t# 验证阶段\n",
    "\t\tmodel.eval()\n",
    "\t\ttest_correct = 0\n",
    "\t\ttest_total = 0\n",
    "\t\ttest_loss = 0.0\n",
    "\t\t\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tpbar = tqdm(test_loader, desc=f'Epoch {epoch+1}/{CFG[\"num_epochs\"]} [Test]')\n",
    "\t\t\tfor inputs, labels in pbar:\n",
    "\t\t\t\tinputs = inputs.to(CFG['device'])\n",
    "\t\t\t\tlabels = labels.to(CFG['device'])\n",
    "\t\t\t\t\n",
    "\t\t\t\toutputs = model(inputs)\n",
    "\t\t\t\tloss = criterion(outputs, labels)\n",
    "\t\t\t\t\n",
    "\t\t\t\ttest_loss += loss.item() * inputs.size(0)\n",
    "\t\t\t\t_, predicted = torch.max(outputs.data, 1)\n",
    "\t\t\t\ttest_total += labels.size(0)\n",
    "\t\t\t\ttest_correct += (predicted == labels).sum().item()\n",
    "\t\t\t\t\n",
    "\t\t\t\tpbar.set_postfix({\n",
    "\t\t\t\t\t'acc': f'{test_correct/test_total:.3f}'\n",
    "\t\t\t\t})\n",
    "\t\t\n",
    "\t\t# 保存最佳模型\n",
    "\t\tepoch_acc = test_correct / test_total\n",
    "\t\tif epoch_acc > best_acc:\n",
    "\t\t\tbest_acc = epoch_acc\n",
    "\t\t\ttorch.save(model.state_dict(), 'best_model.pth')\n",
    "\t\t\tprint(f'New best model saved with acc: {best_acc:.4f}')\n",
    "\n",
    "# 预测并生成结果\n",
    "def predict(model, test_loader):\n",
    "\tmodel.load_state_dict(torch.load('best_model.pth'))\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\tfilenames = []\n",
    "\tpredictions = []\n",
    "\t\n",
    "\twith torch.no_grad():\n",
    "\t\tfor inputs, _ in tqdm(test_loader, desc='Predicting'):\n",
    "\t\t\tinputs = inputs.to(CFG['device'])\n",
    "\t\t\toutputs = model(inputs)\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\tpredictions.extend((preds + 1).cpu().numpy())  # 转回1-based\n",
    "\t\n",
    "\t# 获取文件名\n",
    "\ttest_df = test_loader.dataset.df\n",
    "\tfilenames = test_df.iloc[:, 0].apply(lambda x: x.split('/')[-1]).tolist()\n",
    "\t\n",
    "\t# 写入文件\n",
    "\twith open('submission.txt', 'w') as f:\n",
    "\t\tfor fn, pred in zip(filenames, predictions):\n",
    "\t\t\tf.write(f\"{fn}\\t{pred}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# 准备数据\n",
    "\ttrain_df, test_df = load_data(CFG['csv_name'], CFG['data_path'])\n",
    "\t\n",
    "\t# 创建数据集和数据加载器\n",
    "\ttrain_dataset = MedicineDataset(train_df, train_transform)\n",
    "\ttest_dataset = MedicineDataset(test_df, test_transform)\n",
    "\t\n",
    "\ttrain_loader = DataLoader(\n",
    "\t\ttrain_dataset,\n",
    "\t\tbatch_size=CFG['batch_size'],\n",
    "\t\tshuffle=True,\n",
    "\t\tnum_workers=CFG['num_workers']\n",
    "\t)\n",
    "\t\n",
    "\ttest_loader = DataLoader(\n",
    "\t\ttest_dataset,\n",
    "\t\tbatch_size=CFG['batch_size'],\n",
    "\t\tshuffle=False,\n",
    "\t\tnum_workers=CFG['num_workers']\n",
    "\t)\n",
    "\t\n",
    "\t# 初始化模型\n",
    "\tmodel = models.resnet50(pretrained=True)\n",
    "\tmodel.fc = nn.Linear(model.fc.in_features, CFG['num_classes'])\n",
    "\t\n",
    "\t# 训练模型\n",
    "\ttrain_model(model, train_loader, test_loader)\n",
    "\t\n",
    "\t# 生成预测结果\n",
    "\tpredict(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f656e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, test_dir, transform):\n",
    "\tmodel.eval()\n",
    "\tpredictions = []\n",
    "\t\n",
    "\t# 获取测试图片列表\n",
    "\ttest_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "\t\t\t\t  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\t\n",
    "\t# 创建测试数据加载器\n",
    "\tclass TestDataset(Dataset):\n",
    "\t\tdef __init__(self, image_paths, transform=None):\n",
    "\t\t\tself.image_paths = image_paths\n",
    "\t\t\tself.transform = transform\n",
    "\t\t\t\n",
    "\t\tdef __len__(self):\n",
    "\t\t\treturn len(self.image_paths)\n",
    "\t\t\n",
    "\t\tdef __getitem__(self, idx):\n",
    "\t\t\timage = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "\t\t\tif self.transform:\n",
    "\t\t\t\timage = self.transform(image)\n",
    "\t\t\treturn image, os.path.basename(self.image_paths[idx])\n",
    "\t\n",
    "\ttest_dataset = TestDataset(test_images, transform=transform)\n",
    "\ttest_loader = DataLoader(test_dataset, batch_size=CFG['batch_size'], shuffle=False)\n",
    "\t\n",
    "\t# 进行预测\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, filenames in tqdm(test_loader, desc='Predicting'):\n",
    "\t\t\timages = images.to(CFG['device'])\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\t_, preds = torch.max(outputs.logits, 1)\n",
    "\t\t\t\n",
    "\t\t\tfor fn, pred in zip(filenames, preds.cpu().numpy()):\n",
    "\t\t\t\tpredictions.append((fn, pred + 1))  # 转换回1-based\n",
    "\t\n",
    "\t# 保存结果\n",
    "\twith open('submission.txt', 'w') as f:\n",
    "\t\tfor fn, pred in predictions:\n",
    "\t\t\tf.write(f'{fn}\\t{pred}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "455841bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:  12%|█▏        | 558/4694 [01:23<11:56,  5.77it/s]c:\\Users\\wyz20\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Predicting: 100%|██████████| 4694/4694 [11:41<00:00,  6.69it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 生成提交文件（假设测试图片在test目录下）\n",
    "# 修正 outputs.logits 为 outputs\n",
    "def generate_predictions(model, test_dir, transform):\n",
    "\tmodel.eval()\n",
    "\tpredictions = []\n",
    "\t\n",
    "\t# 获取测试图片列表\n",
    "\ttest_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "\t\t\t\t  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\t\n",
    "\t# 创建测试数据加载器\n",
    "\tclass TestDataset(Dataset):\n",
    "\t\tdef __init__(self, image_paths, transform=None):\n",
    "\t\t\tself.image_paths = image_paths\n",
    "\t\t\tself.transform = transform\n",
    "\t\t\t\n",
    "\t\tdef __len__(self):\n",
    "\t\t\treturn len(self.image_paths)\n",
    "\t\t\n",
    "\t\tdef __getitem__(self, idx):\n",
    "\t\t\timage = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "\t\t\tif self.transform:\n",
    "\t\t\t\timage = self.transform(image)\n",
    "\t\t\treturn image, os.path.basename(self.image_paths[idx])\n",
    "\t\n",
    "\ttest_dataset = TestDataset(test_images, transform=transform)\n",
    "\ttest_loader = DataLoader(test_dataset, batch_size=CFG['batch_size'], shuffle=False)\n",
    "\t\n",
    "\t# 进行预测\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, filenames in tqdm(test_loader, desc='Predicting'):\n",
    "\t\t\timages = images.to(CFG['device'])\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\t_, preds = torch.max(outputs, 1)\n",
    "\t\t\t\n",
    "\t\t\tfor fn, pred in zip(filenames, preds.cpu().numpy()):\n",
    "\t\t\t\tpredictions.append((fn, pred + 1))  # 转换回1-based\n",
    "\t\n",
    "\t# 保存结果\n",
    "\twith open('submission.txt', 'w') as f:\n",
    "\t\tfor fn, pred in predictions:\n",
    "\t\t\tf.write(f'{fn}\\t{pred}\\n')\n",
    "\n",
    "generate_predictions(model, 'chinese-medicine-image/test', test_transform)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
