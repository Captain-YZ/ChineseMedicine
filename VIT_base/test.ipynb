{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff393b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在验证数据完整性...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167017/167017 [00:10<00:00, 16399.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有效数据量: 167017\n",
      "有效类别数: 879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch 1 [Train]:   0%|          | 5/8351 [00:01<46:15,  3.01it/s, loss=6.79]  c:\\Users\\wyz20\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Epoch 1 [Train]: 100%|██████████| 8351/8351 [1:12:58<00:00,  1.91it/s, loss=3.33]\n",
      "Epoch 1 [Val]: 100%|██████████| 2088/2088 [13:00<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 5.3754 | Val Loss: 3.7197 | Val Acc: 40.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|██████████| 8351/8351 [1:07:48<00:00,  2.05it/s, loss=3.41]\n",
      "Epoch 2 [Val]: 100%|██████████| 2088/2088 [13:09<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 2.9090 | Val Loss: 2.3762 | Val Acc: 54.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|██████████| 8351/8351 [1:08:01<00:00,  2.05it/s, loss=3.04] \n",
      "Epoch 3 [Val]: 100%|██████████| 2088/2088 [13:16<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 2.1204 | Val Loss: 2.0144 | Val Acc: 59.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|██████████| 8351/8351 [1:09:20<00:00,  2.01it/s, loss=2.94] \n",
      "Epoch 4 [Val]: 100%|██████████| 2088/2088 [13:18<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 1.7865 | Val Loss: 1.8679 | Val Acc: 61.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|██████████| 8351/8351 [1:08:32<00:00,  2.03it/s, loss=1.59] \n",
      "Epoch 5 [Val]: 100%|██████████| 2088/2088 [13:19<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 1.5633 | Val Loss: 1.7679 | Val Acc: 63.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|██████████| 8351/8351 [1:08:33<00:00,  2.03it/s, loss=2.19] \n",
      "Epoch 6 [Val]: 100%|██████████| 2088/2088 [13:09<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 1.3927 | Val Loss: 1.7139 | Val Acc: 64.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]: 100%|██████████| 8351/8351 [1:07:32<00:00,  2.06it/s, loss=1.71] \n",
      "Epoch 7 [Val]: 100%|██████████| 2088/2088 [13:14<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 1.2440 | Val Loss: 1.7077 | Val Acc: 64.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [Train]: 100%|██████████| 8351/8351 [1:07:23<00:00,  2.07it/s, loss=1.22] \n",
      "Epoch 8 [Val]: 100%|██████████| 2088/2088 [13:16<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 1.1178 | Val Loss: 1.6964 | Val Acc: 64.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [Train]: 100%|██████████| 8351/8351 [1:07:17<00:00,  2.07it/s, loss=0.781]\n",
      "Epoch 9 [Val]: 100%|██████████| 2088/2088 [13:18<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 1.0028 | Val Loss: 1.6980 | Val Acc: 64.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [Train]: 100%|██████████| 8351/8351 [1:06:40<00:00,  2.09it/s, loss=0.429] \n",
      "Epoch 10 [Val]: 100%|██████████| 2088/2088 [13:18<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "Train Loss: 0.9044 | Val Loss: 1.7248 | Val Acc: 64.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 [Train]: 100%|██████████| 8351/8351 [1:05:58<00:00,  2.11it/s, loss=0.546] \n",
      "Epoch 11 [Val]: 100%|██████████| 2088/2088 [13:17<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "Train Loss: 0.8157 | Val Loss: 1.7397 | Val Acc: 64.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 [Train]: 100%|██████████| 8351/8351 [1:07:10<00:00,  2.07it/s, loss=1.08]  \n",
      "Epoch 12 [Val]: 100%|██████████| 2088/2088 [13:30<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "Train Loss: 0.7308 | Val Loss: 1.7589 | Val Acc: 64.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 [Train]: 100%|██████████| 8351/8351 [1:06:59<00:00,  2.08it/s, loss=0.683] \n",
      "Epoch 13 [Val]: 100%|██████████| 2088/2088 [13:33<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "Train Loss: 0.6676 | Val Loss: 1.8086 | Val Acc: 63.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 [Train]: 100%|██████████| 8351/8351 [1:06:38<00:00,  2.09it/s, loss=0.334] \n",
      "Epoch 14 [Val]: 100%|██████████| 2088/2088 [13:32<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "Train Loss: 0.6154 | Val Loss: 1.7935 | Val Acc: 64.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 [Train]: 100%|██████████| 8351/8351 [1:06:35<00:00,  2.09it/s, loss=0.505] \n",
      "Epoch 15 [Val]: 100%|██████████| 2088/2088 [13:28<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "Train Loss: 0.5729 | Val Loss: 1.8402 | Val Acc: 63.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 [Train]: 100%|██████████| 8351/8351 [1:07:51<00:00,  2.05it/s, loss=0.901] \n",
      "Epoch 16 [Val]: 100%|██████████| 2088/2088 [13:24<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "Train Loss: 0.5275 | Val Loss: 1.8616 | Val Acc: 63.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 [Train]: 100%|██████████| 8351/8351 [1:07:10<00:00,  2.07it/s, loss=0.224] \n",
      "Epoch 17 [Val]: 100%|██████████| 2088/2088 [13:28<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "Train Loss: 0.5000 | Val Loss: 1.8963 | Val Acc: 63.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 [Train]: 100%|██████████| 8351/8351 [1:07:06<00:00,  2.07it/s, loss=0.26]  \n",
      "Epoch 18 [Val]: 100%|██████████| 2088/2088 [13:35<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "Train Loss: 0.4725 | Val Loss: 1.9020 | Val Acc: 63.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 [Train]: 100%|██████████| 8351/8351 [1:07:19<00:00,  2.07it/s, loss=0.64]  \n",
      "Epoch 19 [Val]: 100%|██████████| 2088/2088 [13:30<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "Train Loss: 0.4524 | Val Loss: 1.9451 | Val Acc: 63.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 [Train]: 100%|██████████| 8351/8351 [1:08:22<00:00,  2.04it/s, loss=0.127] \n",
      "Epoch 20 [Val]: 100%|██████████| 2088/2088 [13:48<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "Train Loss: 0.4368 | Val Loss: 1.9369 | Val Acc: 63.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 [Train]: 100%|██████████| 8351/8351 [1:08:38<00:00,  2.03it/s, loss=1.01]  \n",
      "Epoch 21 [Val]: 100%|██████████| 2088/2088 [13:46<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30\n",
      "Train Loss: 0.4205 | Val Loss: 1.9505 | Val Acc: 63.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 [Train]: 100%|██████████| 8351/8351 [1:08:39<00:00,  2.03it/s, loss=0.308] \n",
      "Epoch 22 [Val]: 100%|██████████| 2088/2088 [13:36<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "Train Loss: 0.4089 | Val Loss: 1.9811 | Val Acc: 63.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 [Train]: 100%|██████████| 8351/8351 [1:10:40<00:00,  1.97it/s, loss=0.237] \n",
      "Epoch 23 [Val]: 100%|██████████| 2088/2088 [13:41<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30\n",
      "Train Loss: 0.4025 | Val Loss: 1.9973 | Val Acc: 63.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 [Train]: 100%|██████████| 8351/8351 [1:09:14<00:00,  2.01it/s, loss=0.512]  \n",
      "Epoch 24 [Val]: 100%|██████████| 2088/2088 [13:49<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "Train Loss: 0.3810 | Val Loss: 2.0185 | Val Acc: 62.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 [Train]: 100%|██████████| 8351/8351 [1:10:00<00:00,  1.99it/s, loss=0.0655] \n",
      "Epoch 25 [Val]: 100%|██████████| 2088/2088 [13:37<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30\n",
      "Train Loss: 0.3686 | Val Loss: 2.0183 | Val Acc: 63.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 [Train]: 100%|██████████| 8351/8351 [1:09:58<00:00,  1.99it/s, loss=0.334]  \n",
      "Epoch 26 [Val]: 100%|██████████| 2088/2088 [13:38<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "Train Loss: 0.3596 | Val Loss: 2.0213 | Val Acc: 63.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 [Train]: 100%|██████████| 8351/8351 [1:09:32<00:00,  2.00it/s, loss=0.576]  \n",
      "Epoch 27 [Val]: 100%|██████████| 2088/2088 [13:43<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "Train Loss: 0.3565 | Val Loss: 2.0578 | Val Acc: 63.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 [Train]: 100%|██████████| 8351/8351 [1:09:40<00:00,  2.00it/s, loss=0.156]  \n",
      "Epoch 28 [Val]: 100%|██████████| 2088/2088 [13:50<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30\n",
      "Train Loss: 0.3497 | Val Loss: 2.0725 | Val Acc: 63.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 [Train]: 100%|██████████| 8351/8351 [1:09:39<00:00,  2.00it/s, loss=0.18]  \n",
      "Epoch 29 [Val]: 100%|██████████| 2088/2088 [13:39<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "Train Loss: 0.3424 | Val Loss: 2.0424 | Val Acc: 63.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 [Train]: 100%|██████████| 8351/8351 [1:10:04<00:00,  1.99it/s, loss=0.747]  \n",
      "Epoch 30 [Val]: 100%|██████████| 2088/2088 [13:39<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30\n",
      "Train Loss: 0.3361 | Val Loss: 2.0567 | Val Acc: 63.36%\n",
      "Best Validation Accuracy: 64.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 4694/4694 [12:22<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 配置参数\n",
    "CFG = {\n",
    "\t'img_size': 224,\n",
    "\t'batch_size': 16,      # 根据8GB显存调整\n",
    "\t'num_epochs': 30,\n",
    "\t'lr': 3e-5,\n",
    "\t'num_workers': 0,      # Windows系统需要设置为0\n",
    "\t'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "\t'num_classes': 881,\n",
    "\t'seed': 42\n",
    "}\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(CFG['seed'])\n",
    "\n",
    "# 数据预处理\n",
    "train_transform = transforms.Compose([\n",
    "\ttransforms.RandomResizedCrop(CFG['img_size']),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.RandomRotation(15),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "\ttransforms.Resize(CFG['img_size']),\n",
    "\ttransforms.CenterCrop(CFG['img_size']),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 自定义数据集类\n",
    "# 修正后的MedicineDataset类\n",
    "class MedicineDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)  # 确保索引正确\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 确保标签为torch.int64类型\n",
    "        return image, torch.as_tensor(label, dtype=torch.long)\n",
    "\n",
    "# 加载数据\n",
    "def load_data(csv_path, root_dir):\n",
    "    # 改进的CSV读取方式\n",
    "    df = pd.read_csv(csv_path, header=0)  # 使用第一行作为列头\n",
    "    df = df.rename(columns={'ID': 'path', 'Label': 'label'})  # 规范列名\n",
    "    \n",
    "    # 数据类型转换\n",
    "    convert_dict = {'path': str, 'label': int}\n",
    "    df = df.astype(convert_dict)\n",
    "    \n",
    "    # 路径修正（根据实际文件结构可能需要调整）\n",
    "    df['path'] = df['path'].apply(lambda x: os.path.join(root_dir, x))\n",
    "    \n",
    "    # 验证数据有效性\n",
    "    print(\"正在验证数据完整性...\")\n",
    "    valid_samples = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        if os.path.exists(row['path']):\n",
    "            valid_samples.append(idx)\n",
    "        else:\n",
    "            print(f\"警告：缺失文件 {row['path']}\")\n",
    "    df = df.loc[valid_samples]\n",
    "    \n",
    "    # 过滤无效类别（每个类别至少需要2个样本）\n",
    "    label_counts = df['label'].value_counts()\n",
    "    valid_labels = label_counts[label_counts >= 2].index\n",
    "    df = df[df['label'].isin(valid_labels)]\n",
    "    \n",
    "    print(f\"有效数据量: {len(df)}\")\n",
    "    print(f\"有效类别数: {df['label'].nunique()}\")\n",
    "    \n",
    "    # 转换为0-based标签\n",
    "    df['label'] = df['label'] - 1\n",
    "    \n",
    "    # 分层划分数据集\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=0.2,\n",
    "        stratify=df['label'],\n",
    "        random_state=CFG['seed']\n",
    "    )\n",
    "    return train_df, val_df\n",
    "# 创建模型\n",
    "def create_model():\n",
    "\tmodel = ViTForImageClassification.from_pretrained(\n",
    "\t\t'google/vit-base-patch16-224-in21k',\n",
    "\t\tnum_labels=CFG['num_classes'],\n",
    "\t\tignore_mismatched_sizes=True\n",
    "\t)\n",
    "\treturn model.to(CFG['device'])\n",
    "\n",
    "# 训练函数\n",
    "def train_model(model, train_loader, val_loader):\n",
    "\toptimizer = torch.optim.AdamW(model.parameters(), lr=CFG['lr'])\n",
    "\tcriterion = nn.CrossEntropyLoss()\n",
    "\t\n",
    "\tbest_acc = 0.0\n",
    "\tfor epoch in range(CFG['num_epochs']):\n",
    "\t\t# 训练阶段\n",
    "\t\tmodel.train()\n",
    "\t\ttrain_loss = 0.0\n",
    "\t\tprogress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1} [Train]')\n",
    "\t\tfor images, labels in progress_bar:\n",
    "\t\t\timages = images.to(CFG['device'])\n",
    "\t\t\tlabels = labels.to(CFG['device'])\n",
    "\t\t\t\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\t\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\tloss = criterion(outputs.logits, labels)\n",
    "\t\t\t\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\ttrain_loss += loss.item() * images.size(0)\n",
    "\t\t\tprogress_bar.set_postfix(loss=loss.item())\n",
    "\t\t\n",
    "\t\t# 验证阶段\n",
    "\t\tmodel.eval()\n",
    "\t\tval_loss = 0.0\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1} [Val]'):\n",
    "\t\t\t\timages = images.to(CFG['device'])\n",
    "\t\t\t\tlabels = labels.to(CFG['device'])\n",
    "\t\t\t\t\n",
    "\t\t\t\toutputs = model(images)\n",
    "\t\t\t\tloss = criterion(outputs.logits, labels)\n",
    "\t\t\t\t\n",
    "\t\t\t\tval_loss += loss.item() * images.size(0)\n",
    "\t\t\t\t_, predicted = torch.max(outputs.logits, 1)\n",
    "\t\t\t\ttotal += labels.size(0)\n",
    "\t\t\t\tcorrect += (predicted == labels).sum().item()\n",
    "\t\t\n",
    "\t\t# 打印统计信息\n",
    "\t\ttrain_loss = train_loss / len(train_loader.dataset)\n",
    "\t\tval_loss = val_loss / len(val_loader.dataset)\n",
    "\t\tval_acc = 100 * correct / total\n",
    "\t\tprint(f'Epoch {epoch+1}/{CFG[\"num_epochs\"]}')\n",
    "\t\tprint(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "\t\t\n",
    "\t\t# 保存最佳模型\n",
    "\t\tif val_acc > best_acc:\n",
    "\t\t\tbest_acc = val_acc\n",
    "\t\t\ttorch.save(model.state_dict(), 'best_vit_model.pth')\n",
    "\t\n",
    "\tprint(f'Best Validation Accuracy: {best_acc:.2f}%')\n",
    "\n",
    "# 生成预测结果\n",
    "def generate_predictions(model, test_dir, transform):\n",
    "\tmodel.eval()\n",
    "\tpredictions = []\n",
    "\t\n",
    "\t# 获取测试图片列表\n",
    "\ttest_images = [os.path.join(test_dir, f) for f in os.listdir(test_dir) \n",
    "\t\t\t\t  if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\t\n",
    "\t# 创建测试数据加载器\n",
    "\tclass TestDataset(Dataset):\n",
    "\t\tdef __init__(self, image_paths, transform=None):\n",
    "\t\t\tself.image_paths = image_paths\n",
    "\t\t\tself.transform = transform\n",
    "\t\t\t\n",
    "\t\tdef __len__(self):\n",
    "\t\t\treturn len(self.image_paths)\n",
    "\t\t\n",
    "\t\tdef __getitem__(self, idx):\n",
    "\t\t\timage = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "\t\t\tif self.transform:\n",
    "\t\t\t\timage = self.transform(image)\n",
    "\t\t\treturn image, os.path.basename(self.image_paths[idx])\n",
    "\t\n",
    "\ttest_dataset = TestDataset(test_images, transform=transform)\n",
    "\ttest_loader = DataLoader(test_dataset, batch_size=CFG['batch_size'], shuffle=False)\n",
    "\t\n",
    "\t# 进行预测\n",
    "\twith torch.no_grad():\n",
    "\t\tfor images, filenames in tqdm(test_loader, desc='Predicting'):\n",
    "\t\t\timages = images.to(CFG['device'])\n",
    "\t\t\toutputs = model(images)\n",
    "\t\t\t_, preds = torch.max(outputs.logits, 1)\n",
    "\t\t\t\n",
    "\t\t\tfor fn, pred in zip(filenames, preds.cpu().numpy()):\n",
    "\t\t\t\tpredictions.append((fn, pred + 1))  # 转换回1-based\n",
    "\t\n",
    "\t# 保存结果\n",
    "\twith open('submission.txt', 'w') as f:\n",
    "\t\tfor fn, pred in predictions:\n",
    "\t\t\tf.write(f'{fn}\\t{pred}\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# 数据准备\n",
    "\ttrain_df, val_df = load_data('chinese-medicine-image/train_labels.csv', 'chinese-medicine-image')\n",
    "\t\n",
    "\t# 创建数据集\n",
    "\ttrain_dataset = MedicineDataset(train_df, train_transform)\n",
    "\tval_dataset = MedicineDataset(val_df, val_transform)\n",
    "\t# 创建数据加载器\n",
    "\ttrain_loader = DataLoader(train_dataset, batch_size=CFG['batch_size'], shuffle=True)\n",
    "\tval_loader = DataLoader(val_dataset, batch_size=CFG['batch_size'], shuffle=False)\n",
    "\t\n",
    "\t# 初始化模型\n",
    "\tmodel = create_model()\n",
    "\t\n",
    "\t# 开始训练\n",
    "\ttrain_model(model, train_loader, val_loader)\n",
    "\t\n",
    "\t# 加载最佳模型进行预测\n",
    "\tmodel.load_state_dict(torch.load('best_vit_model.pth'))\n",
    "\t\n",
    "\t# 生成提交文件（假设测试图片在test目录下）\n",
    "\tgenerate_predictions(model, 'chinese-medicine-image/test', val_transform)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
